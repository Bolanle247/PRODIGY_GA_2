# PRODIGY_GA_2
Text-to-image generation using DALL·E-mini (Craiyon)
## Project Overview
This project demonstrates how a pre-trained generative model (DALL·E-mini, also known as Craiyon) can be used to generate images from text prompts. The goal is to show how descriptive natural language can be converted into visual content without training a model or writing code.

---

## Tool Used
- **DALL·E-mini (Craiyon)**
- Type: Pre-trained text-to-image generative model
- Accessed via web interface

---

## Project Objective
To generate an image with:
- A blue gradient background
- A glowing circular shape
- A modern, AI-inspired design

---

## Steps Followed

1. Opened the Craiyon (DALL·E-mini) web application.
2. Wrote a clear and descriptive text prompt.
3. Generated multiple images from the prompt.
4. Selected the best image based on clarity and relevance.
5. Saved the generated image for documentation.

---

## Text Prompt Used

"A glowing circular shape in the center of a smooth blue gradient background, modern AI design, digital art"

---

## Generated Output
The model generated multiple images based on the prompt. One image was selected that best matched the description and visual quality requirements.


## Explanation
DALL·E-mini is a pre-trained text-to-image model that generates images by learning associations between text and visual patterns. When a prompt is provided, the model predicts and constructs an image that aligns with the semantic meaning of the text.

---

## Conclusion
This project shows how AI models can translate human language into visual representations. It highlights the accessibility of generative AI tools for creative and academic purposes.
